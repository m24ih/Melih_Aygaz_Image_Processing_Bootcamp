{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e3ebe8-b0df-48bd-b227-6be19be8ea10",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Sistem belirtilen dosyayı bulamıyor: 'C:\\\\Users\\\\Melih\\\\AppData\\\\Roaming\\\\Python\\\\Python310\\\\site-packages\\\\tensorflow-plugins'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\__init__.py:438\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _s \u001b[38;5;129;01min\u001b[39;00m _site_packages_dirs:\n\u001b[0;32m    437\u001b[0m   _plugin_dir \u001b[38;5;241m=\u001b[39m _os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(_s, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow-plugins\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_os\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_plugin_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    439\u001b[0m     _ll\u001b[38;5;241m.\u001b[39mload_library(_plugin_dir)\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;66;03m# Load Pluggable Device Library\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd2b53-5191-4888-a2a1-08426229cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dictionary to hold paths for each animal\n",
    "image_paths = {}\n",
    "\n",
    "# Base directory for your dataset\n",
    "base_path = \"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/JPEGImages/\"\n",
    "\n",
    "# List of animals to search for\n",
    "animals = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\n",
    "\n",
    "# Traverse the directory structure\n",
    "for dirname, _, filenames in os.walk(base_path):\n",
    "    for animal in animals:\n",
    "        # Check if the current directory contains the animal's name\n",
    "        if animal in dirname:\n",
    "            # Initialize the list if the animal is encountered for the first time\n",
    "            if animal not in image_paths:\n",
    "                image_paths[animal] = []\n",
    "            # Add all image paths for the current animal\n",
    "            for filename in filenames:\n",
    "                image_paths[animal].append(os.path.join(dirname, filename))\n",
    "\n",
    "# Print the paths for verification\n",
    "for animal, paths in image_paths.items():\n",
    "    print(f\"{animal}: {len(paths)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67362e70-a71f-4adb-b156-a6a6042bd8d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for animal, paths in image_paths.items():\n",
    "    print(f\"{animal}: {paths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440aa918-e929-4572-a0d9-9982888c68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Çıkış dizini (işlenmiş resimler için)\n",
    "output_path = \"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/processed_images\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Resim boyutu (model girişine göre)\n",
    "image_size = (128, 128)  # Örnek: 128x128\n",
    "\n",
    "# Dizin yapısını dolaşarak ilk 650 resmi seç\n",
    "for dirname, _, filenames in os.walk(base_path):\n",
    "    for animal in animals:\n",
    "        if animal in dirname:\n",
    "            if animal not in image_paths:\n",
    "                image_paths[animal] = []\n",
    "            for filename in filenames:\n",
    "                image_paths[animal].append(os.path.join(dirname, filename))\n",
    "\n",
    "# Her sınıf için yalnızca ilk 650 resmi işleyin\n",
    "for animal, paths in image_paths.items():\n",
    "    selected_paths = paths[:650]\n",
    "    animal_output_dir = os.path.join(output_path, animal)\n",
    "    os.makedirs(animal_output_dir, exist_ok=True)\n",
    "\n",
    "    for i, image_path in enumerate(selected_paths):\n",
    "        try:\n",
    "            # Resmi yükle\n",
    "            img = cv2.imread(image_path)\n",
    "\n",
    "            # Yeniden boyutlandır ve normalize et\n",
    "            img_resized = cv2.resize(img, image_size)\n",
    "            img_normalized = img_resized / 255.0\n",
    "\n",
    "            # Yeni dosya yolunu oluştur\n",
    "            output_file = os.path.join(animal_output_dir, f\"{i+1}.jpg\")\n",
    "\n",
    "            # Normalize edilmiş resmi kaydet\n",
    "            cv2.imwrite(output_file, (img_normalized * 255).astype(\"uint8\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "\n",
    "            # Belleği temizle\n",
    "            del img\n",
    "            del manipulated_img\n",
    "            gc.collect()  # Çöp toplama işlemi başlat\n",
    "\n",
    "\n",
    "print(\"Resimler başarıyla işlendi ve kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c8471c-b0ee-4d0e-8f83-3de52f26ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory, image_size):\n",
    "    \"\"\"\n",
    "    Belirtilen dizindeki tüm görüntüleri yükler ve etiketleriyle birlikte döndürür.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Görüntülerin bulunduğu ana dizin.\n",
    "        image_size (tuple): Yeniden boyutlandırılacak görüntü boyutu (width, height).\n",
    "\n",
    "    Returns:\n",
    "        tuple: X (görüntülerin numpy dizisi), y (etiketlerin numpy dizisi).\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    label_map = {}  # Etiketleme için sınıf isimlerini haritalandır\n",
    "    current_label = 0\n",
    "\n",
    "    for subdir in os.listdir(directory):\n",
    "        subdir_path = os.path.join(directory, subdir)\n",
    "\n",
    "        if os.path.isdir(subdir_path):\n",
    "            if subdir not in label_map:\n",
    "                label_map[subdir] = current_label\n",
    "                current_label += 1\n",
    "\n",
    "            for file in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, file)\n",
    "                if file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    try:\n",
    "                        # Görüntüyü yükle ve yeniden boyutlandır\n",
    "                        img = cv2.imread(file_path)\n",
    "                        img_resized = cv2.resize(img, image_size)\n",
    "                        X.append(img_resized)\n",
    "                        y.append(label_map[subdir])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {file_path}: {e}\")\n",
    "\n",
    "    X = np.array(X, dtype=np.float32) / 255.0\n",
    "    y = np.array(y, dtype=np.int32)\n",
    "    return X, y\n",
    "\n",
    "def manipulate_image(image):\n",
    "    \"\"\"\n",
    "    Görüntüyü manipüle eden bir fonksiyon.\n",
    "    \"\"\"\n",
    "    # Parlaklık artırma\n",
    "    manipulated_img = cv2.convertScaleAbs(image, alpha=1.5, beta=30)\n",
    "    \n",
    "    # Beyaz dengesi\n",
    "    wb = cv2.xphoto.createSimpleWB()\n",
    "    manipulated_img = wb.balanceWhite(manipulated_img)\n",
    "\n",
    "    # Kontrast artırma\n",
    "    lab = cv2.cvtColor(manipulated_img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = cv2.equalizeHist(l)\n",
    "    lab = cv2.merge([l, a, b])\n",
    "    manipulated_img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return manipulated_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9488b4-3df5-48c9-b2df-10e5ae0c181c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_manipulated_images(input_dir, output_dir, image_size):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for animal in os.listdir(input_dir):\n",
    "        animal_dir = os.path.join(input_dir, animal)\n",
    "        if os.path.isdir(animal_dir):\n",
    "            output_animal_dir = os.path.join(output_dir, animal)\n",
    "            os.makedirs(output_animal_dir, exist_ok=True)\n",
    "\n",
    "            for image_file in os.listdir(animal_dir):\n",
    "                image_path = os.path.join(animal_dir, image_file)\n",
    "                if image_file.endswith((\".jpg\", \".png\")):\n",
    "                    try:\n",
    "                        # Resmi oku\n",
    "                        img = cv2.imread(image_path)\n",
    "\n",
    "                        # Manipüle et\n",
    "                        manipulated_img = manipulate_image(img)\n",
    "\n",
    "                        # Yeni dosya yolunu oluştur\n",
    "                        output_image_path = os.path.join(output_animal_dir, image_file)\n",
    "\n",
    "                        # Manipüle edilmiş görüntüyü kaydet\n",
    "                        cv2.imwrite(output_image_path, manipulated_img)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {image_path}: {e}\")\n",
    "    gc.collect()\n",
    "\n",
    "# Manipüle edilmiş görüntülerin kaydedileceği klasör\n",
    "output_dir = \"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/manipulated_images\"\n",
    "save_manipulated_images(\"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/processed_images\", output_dir, (128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13c605-4981-452e-9d7d-da1e31946d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İşlenmiş ve manipüle edilmiş verileri yükle\n",
    "processed_images_dir = \"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/processed_images\"\n",
    "manipulated_images_dir = \"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/manipulated_images\"\n",
    "image_size = (128, 128)\n",
    "\n",
    "# Verileri yükle\n",
    "X_processed, y_processed = load_images(processed_images_dir, image_size)\n",
    "X_manipulated, y_manipulated = load_images(manipulated_images_dir, image_size)\n",
    "\n",
    "# Verileri birleştir\n",
    "X_combined = np.concatenate((X_processed, X_manipulated))\n",
    "y_combined = np.concatenate((y_processed, y_manipulated))\n",
    "\n",
    "print(f\"Combined X shape: {X_combined.shape}, Combined y shape: {y_combined.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7dcbd0-6273-482e-9354-b9175326e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Veri setini böl\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model tanımla\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(set(y_combined)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Modeli eğit\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Test seti üzerinde değerlendirme\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c41f8-051c-41f4-84da-2b42fdbcc5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli kaydet\n",
    "model.save(\"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/saved_models/combined_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61181b62-9254-4335-a599-875a23633626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipüle edilmiş verileri yükle\n",
    "manipulated_images_dir = \"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/manipulated_images\"\n",
    "image_size = (128, 128)\n",
    "\n",
    "X_manipulated, y_manipulated = load_images(manipulated_images_dir, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243a055-e3d6-4e08-a70f-93f6c355e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Kaydedilmiş modeli yükle\n",
    "model = load_model(\"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/saved_models/combined_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667b64a-d628-49ee-b23c-d7d1e88087b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli manipüle edilmiş verilerle test et\n",
    "test_loss, test_acc = model.evaluate(X_manipulated, y_manipulated, verbose=2)\n",
    "print(f\"Manipüle edilmiş verilerle test doğruluğu: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b4c4e-31e2-44cc-a7bc-592a51b1a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipüle edilmiş verilerde tahmin yap\n",
    "predictions = model.predict(X_manipulated)\n",
    "\n",
    "# Her tahmin için en yüksek olasılığa sahip sınıfı seç\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Doğru ve yanlış tahminleri analiz et\n",
    "correct_predictions = (predicted_classes == y_manipulated).sum()\n",
    "total_samples = len(y_manipulated)\n",
    "print(f\"Doğru tahmin edilen örnek sayısı: {correct_predictions}/{total_samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1323db34-ab05-497f-8980-2e3e05436058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Yanlış tahmin edilenleri bulun\n",
    "incorrect_indices = np.where(predicted_classes != y_manipulated)[0]\n",
    "\n",
    "# Yanlış tahmin edilenlerden bazılarını görselleştir\n",
    "random_indices = np.random.choice(incorrect_indices, 5, replace=False)\n",
    "\n",
    "for idx in random_indices:\n",
    "    plt.imshow(X_manipulated[idx])\n",
    "    plt.title(f\"Gerçek: {y_manipulated[idx]}, Tahmin: {predicted_classes[idx]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b6f7f-979d-4bfd-bae3-59f0348c40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doğru tahmin edilenleri bulun\n",
    "correct_indices = np.where(predicted_classes == y_manipulated)[0]\n",
    "\n",
    "# Doğru tahmin edilenlerden bazılarını görselleştir\n",
    "random_indices = np.random.choice(correct_indices, 5, replace=False)\n",
    "\n",
    "for idx in random_indices:\n",
    "    plt.imshow(X_manipulated[idx])\n",
    "    plt.title(f\"Gerçek: {y_manipulated[idx]}, Tahmin: {predicted_classes[idx]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6997f5-6787-4533-ac63-3cf5937d750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wb_images(image):\n",
    "    \"\"\"\n",
    "    Gray World algoritmasını uygulayarak renk sabitliği yapar.\n",
    "    \"\"\"\n",
    "    # Her renk kanalının ortalamasını hesapla\n",
    "    avg_b = np.mean(image[:, :, 0])  # Blue\n",
    "    avg_g = np.mean(image[:, :, 1])  # Green\n",
    "    avg_r = np.mean(image[:, :, 2])  # Red\n",
    "    \n",
    "    # Ortalama parlaklık\n",
    "    avg_gray = (avg_b + avg_g + avg_r) / 3\n",
    "    \n",
    "    # Kanalları normalize et\n",
    "    scale_b = avg_gray / avg_b\n",
    "    scale_g = avg_gray / avg_g\n",
    "    scale_r = avg_gray / avg_r\n",
    "\n",
    "    # Görüntüyü normalize et\n",
    "    image[:, :, 0] = np.clip(image[:, :, 0] * scale_b, 0, 255)\n",
    "    image[:, :, 1] = np.clip(image[:, :, 1] * scale_g, 0, 255)\n",
    "    image[:, :, 2] = np.clip(image[:, :, 2] * scale_r, 0, 255)\n",
    "\n",
    "    return image.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bcd112-8a31-4880-a8ad-e028a7ea9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipüle edilmiş resimlerin ve sonuçların dizinleri\n",
    "manipulated_images_dir = \"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/manipulated_images\"\n",
    "output_dir = \"C:/Users/Melih/Coding/Bootcamp/Melih_Aygaz_Visual_Bootcamp/AwA2-data/Animals_with_Attributes2/wb_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Tüm manipüle edilmiş test setini renk sabitliği ile işle ve kaydet\n",
    "for root, _, files in os.walk(manipulated_images_dir):\n",
    "    for file in files:\n",
    "        input_image_path = os.path.join(root, file)\n",
    "\n",
    "        # Çıkış klasör yapısını korumak için alt klasörler oluştur\n",
    "        relative_path = os.path.relpath(root, manipulated_images_dir)\n",
    "        output_subdir = os.path.join(output_dir, relative_path)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "        \n",
    "        output_image_path = os.path.join(output_subdir, file)\n",
    "\n",
    "        # Görüntüyü yükle\n",
    "        image = cv2.imread(input_image_path)\n",
    "        if image is not None:\n",
    "            # Gray World algoritması uygula\n",
    "            wb_image = get_wb_images(image)\n",
    "            # Sonucu kaydet\n",
    "            cv2.imwrite(output_image_path, wb_image)\n",
    "\n",
    "print(\"Renk sabitliği tüm manipüle edilmiş test setine uygulandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a640a2f0-f1b1-4202-85d7-7ceb401564e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wb_images(wb_images_dir, image_size):\n",
    "    X = []\n",
    "    y = []\n",
    "    for root, _, files in os.walk(wb_images_dir):\n",
    "        for file in files:\n",
    "            image_path = os.path.join(root, file)\n",
    "            label = os.path.basename(root)  # Klasör adını etiket olarak al\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, image_size)\n",
    "                X.append(image)\n",
    "                y.append(animals.index(label))  # `animals` listesine göre etiketle\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Kullanım\n",
    "wb_X_test, wb_y_test = load_wb_images(output_dir, (128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb2d3cd-24cb-4c99-a8ad-074df9d8d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize et\n",
    "wb_X_test = wb_X_test / 255.0\n",
    "\n",
    "# Modelle test et\n",
    "test_loss, test_acc = model.evaluate(wb_X_test, wb_y_test)\n",
    "print(f\"White balance applied test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d104d-6065-4162-bce3-7f8e0f930ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
